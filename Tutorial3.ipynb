{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesFrag - Tutorial 3: Computation of GMM estimates using OpenQuake\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bodlukas/BayesFrag/blob/main/Tutorial3.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "BayesFrag is a tool to perform Bayesian parameter estimation for empirical seismic fragility models. The tool accounts for uncertainty in the ground motion intensity measures (IMs) which caused the observed damage. The methodology is presented in\n",
    "\n",
    "> Bodenmann L., Baker J. , Stojadinovic B. (2023): \"Accounting for ground motion uncertainty in empirical seismic fragility modeling\". INCLUDE LINK\n",
    "\n",
    "This notebook and further supporting codes are published on [GitHub](https://github.com/bodlukas/BayesFrag) and Zenodo (doi: LINK)\n",
    "\n",
    "To avoid any additional dependency on a specific ground motion model (GMM) library, the GMM estimates for the IM of interest are computed outside of BayesFrag and prior to the actual fragility model estimation. Conditional on earthquake rupture characteristics, $\\mathbf{rup}$, we consider the log-transformed IM at site $i$ to be normally distributed, i.e., \n",
    "\n",
    "$p(\\ln im_i|\\mathbf{rup}) = \\mathcal{N}\\left(\\mu_i\\, , \\, \\sqrt{\\tau_i^2 + \\phi_i^2}\\right)$ ,\n",
    "\n",
    "where $\\mu_i$ is the mean, $\\tau_i$ is the standard deviation of between-event residuals, and $\\phi_i$, is the standard deviation of within-event residuals. To perform fragility model estimation, BayesFrag requires that $\\mu_i$, $\\tau_i$, and $\\phi_i$ are available at the sites of: (1) seismic network stations, and (2) surveyed buildings. This tutorial explains how to perform these computations using [OpenQuake](https://github.com/gem/oq-engine#openquake-engine) as the GMM library and based on the example of the 2009 L'Aquila (Italy) earthquake. \n",
    "\n",
    "Note that OpenQuake - or any other GMM library - is not a part of BayesFrag and has to be installed separately, for example in a different virtual environment. Alternatively, users can open this tutorial on a hosted Jupyter notebook service (e.g., Google Colab). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "If the notebook is opened on google colab, we install [OpenQuake](https://github.com/gem/oq-engine#openquake-engine) and clone the [BayesFrag repository](https://github.com/bodlukas/BayesFrag) for data access. This may take a few minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"): # Check whether notebook runs on colab.\n",
    "  !pip install openquake.engine>=3.15.0\n",
    "  !git clone https://github.com/bodlukas/BayesFrag.git\n",
    "  %cd BayesFrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import openquake.hazardlib as oq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify settings\n",
    "\n",
    "Specify the IM of interest (for PGA use 'PGA', for SA(T=0.3s) use 'SAT0_300'), and the GMM. This tutorial covers the two GMMs used in the manuscript: 'BindiEtAl2011' and 'ChiouYoungs2014Italy'. Analysts can use any other GMM that is available in OpenQuake, with slight changes to this notebook that will be explained throughout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join('data', 'tutorial2', '')\n",
    "\n",
    "args = {\n",
    "    'IM': 'SAT0_300',\n",
    "    'GMM': 'BindiEtAl2011',\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify earthquake rupture \n",
    "\n",
    "Here we specify the rupture characteristics from the 2009 L'Aquila earthquake as obtained from the Engineering Strong Motion database, [ESM](https://esm-db.eu/#/event/IT-2009-0009). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = oq.geo.point.Point\n",
    "PlanarSurface = oq.geo.surface.planar.PlanarSurface\n",
    "MultiSurface = oq.geo.surface.multi.MultiSurface\n",
    "BaseRupture = oq.source.rupture.BaseRupture\n",
    "\n",
    "f = open(path_data + 'rupture.json')\n",
    "rup_temp = json.load(f)\n",
    "f.close()\n",
    "rup_geom_json = rup_temp['features'][0]['geometry']\n",
    "rup_geom = np.array(rup_geom_json['coordinates'][0][0])[:-1,:]\n",
    "\n",
    "rupture_surface = PlanarSurface.from_corner_points(\n",
    "    top_left = Point(rup_geom[0, 0], rup_geom[0, 1], rup_geom[0, 2]),\n",
    "    top_right = Point(rup_geom[1, 0], rup_geom[1, 1], rup_geom[1, 2]),\n",
    "    bottom_right = Point(rup_geom[2, 0], rup_geom[2, 1], rup_geom[2, 2]),\n",
    "    bottom_left = Point(rup_geom[3, 0], rup_geom[3, 1], rup_geom[3, 2]),\n",
    ")\n",
    "rupture = BaseRupture(mag = 6.1, rake = -90.0, \n",
    "                    tectonic_region_type = 'Active Shallow Crust', \n",
    "                    hypocenter = Point(longitude = 13.380, \n",
    "                                        latitude = 42.342,\n",
    "                                        depth = 8.3),\n",
    "                    surface = rupture_surface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import site information\n",
    "\n",
    "**Station data**\n",
    "\n",
    "Below, we import the station data file and print the available attributes, which are:\n",
    "- id: Station identifier\n",
    "- Longitude, Latitude in decimal degrees\n",
    "- vs30: time-averaged shear wave velocity in m/s\n",
    "- vs30measured: A boolean flag, whether vs30 was measured or deduced from other informations\n",
    "\n",
    "Besides this information, the station data also contains observed intensity measures (IMs) as processed from the ground motion recordings. In this example, we have data for four IMs: PGA, SA(0.2s), SA(0.3s), and SA(0.6s). Each of these IMs were processed according to two IM definitions: the geometric mean and the rotD50. GMMs are derived for a specific IM definition and if we aim to include the station observations we should extract the correct definition of the employed GMM. This is discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'Longitude' 'Latitude' 'vs30' 'vs30measured' 'rotD50_logPGA'\n",
      " 'geoM_logPGA' 'rotD50_logSAT0_200' 'geoM_logSAT0_200'\n",
      " 'rotD50_logSAT0_300' 'geoM_logSAT0_300' 'rotD50_logSAT0_600'\n",
      " 'geoM_logSAT0_600']\n"
     ]
    }
   ],
   "source": [
    "dfstations = pd.read_csv(path_data + 'stations.csv')\n",
    "print(dfstations.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Damage survey data**\n",
    "\n",
    "Below, we import the station data file and print the available attributes, which are:\n",
    "- id: Station identifier\n",
    "- Longitude, Latitude in decimal degrees\n",
    "- vs30: time-averaged shear wave velocity in the upper-most 30 meters of soil in m/s\n",
    "- BuildingClass: Used for fragility function estimation (-> see Tutorials 1 and 2)\n",
    "- DamageState: Used for fragility function estimation (-> see Tutorials 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'Longitude' 'Latitude' 'vs30' 'BuildingClass' 'DamageState']\n"
     ]
    }
   ],
   "source": [
    "dfsurvey = pd.read_csv(path_data + 'survey.csv')\n",
    "print(dfsurvey.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute GMM estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OpenQuake GMMs: Modify this to include another GMM.\n",
    "if args['GMM'] == 'BindiEtAl2011':\n",
    "    gmm = oq.gsim.bindi_2011.BindiEtAl2011()\n",
    "elif args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "    gmm = oq.gsim.chiou_youngs_2014.ChiouYoungs2014Italy()\n",
    "\n",
    "# Extract whether IM is defined for the geometric mean or RotD50\n",
    "im_definition = gmm.DEFINED_FOR_INTENSITY_MEASURE_COMPONENT.value\n",
    "if im_definition == 'Average Horizontal':\n",
    "    obs_str = 'geoM_log' + args['IM']\n",
    "elif im_definition == 'Average Horizontal (RotD50)':\n",
    "    obs_str = 'rotD50_log' + args['IM']\n",
    "\n",
    "# Import OpenQuake IMs\n",
    "if args['IM'] == 'PGA':\n",
    "    im_list = [oq.imt.PGA()]\n",
    "else:\n",
    "    T = float('.'.join( args['IM'][3:].split('_') )) \n",
    "    im_list = [oq.imt.SA(T)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrapper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiazimuth(rupture, sites_mesh):\n",
    "    '''\n",
    "    Computes epicentral azimuth which is required for the spatial \n",
    "    correlation model of BodenmannEtAl2023. See also the corresponding\n",
    "    documentation in bayesfrag/spatialcorrelation.py \n",
    "    '''\n",
    "    lon, lat = rupture.hypocenter.longitude, rupture.hypocenter.latitude\n",
    "    lons, lats = sites_mesh.lons, sites_mesh.lats    \n",
    "    return oq.geo.geodetic.fast_azimuth(lon, lat, lons, lats)\n",
    "\n",
    "def get_RuptureContext(rupture, sites_mesh, sites_vs30, \n",
    "                sites_vs30measured=None, sites_z1pt0=None):\n",
    "    '''\n",
    "    Compute the required source and site inputs required for the specified \n",
    "    GMMs. This includes the source-to-site distances.\n",
    "    This may have to be modified if you want to include other GMMs.\n",
    "    '''\n",
    "    rctx = oq.contexts.RuptureContext()\n",
    "    rctx.rjb = rupture.surface.get_joyner_boore_distance(sites_mesh)\n",
    "    rctx.rrup = rupture.surface.get_min_distance(sites_mesh)\n",
    "    rctx.vs30 = sites_vs30\n",
    "    rctx.mag = rupture.mag * np.ones_like(rctx.rjb)\n",
    "    rctx.rake = rupture.rake * np.ones_like(rctx.rjb)\n",
    "    rctx.rx = rupture.surface.get_rx_distance(sites_mesh)\n",
    "    rctx.ztor = rupture.surface.get_top_edge_depth() * np.ones_like(rctx.rjb)\n",
    "    rctx.dip = rupture.surface.get_dip() * np.ones_like(rctx.rjb)\n",
    "    if sites_z1pt0 is None:\n",
    "        rctx.z1pt0 = -7.15/4 * np.log( (sites_vs30**4 + 571**4) / (1360**4 + 571**4) )\n",
    "    else: \n",
    "        rctx.z1pt0 = sites_z1pt0\n",
    "    if sites_vs30measured is None:\n",
    "        rctx.vs30measured = False\n",
    "    else:\n",
    "        rctx.vs30measured = sites_vs30measured\n",
    "    return rctx    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gmm_estimates(gmm, im_list, rupture, df, stations=False):\n",
    "    n = len(df) # Number of sites\n",
    "    nim = len(im_list) # Number of IMs: Here 1!\n",
    "\n",
    "    sites_mesh = oq.geo.mesh.Mesh(df['Longitude'].values, \n",
    "                                df['Latitude'].values, depths=None)\n",
    "    \n",
    "    if 'vs30measured' not in df.columns.values: df['vs30measured'] = False\n",
    "    \n",
    "    rupture_context = get_RuptureContext(rupture, sites_mesh, \n",
    "                                sites_vs30 = df['vs30'].values, \n",
    "                                sites_vs30measured = df['vs30measured'].values)\n",
    "    \n",
    "    mean = sigma = tau = phi = np.zeros([nim, n])\n",
    "    gmm.compute(rupture_context, im_list, mean, sigma, tau, phi)\n",
    "    res = {'mu_logIM': mean.squeeze(), 'tau_logIM': tau.squeeze(), 'phi_logIM': phi.squeeze()}\n",
    "\n",
    "    if args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "        # Epicentral azimuth is required for spatial correlation model of BodenmannEtAl2023.\n",
    "        # This correlation model is used together with the GMM of ChiouYoungs2014Italy.\n",
    "        res['epiazimuth'] = get_epiazimuth(rupture, sites_mesh).squeeze()\n",
    "\n",
    "    if stations: res['obs_logIM'] = df[obs_str].values\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Station and survey data sites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM estimates at sites of seismic network stations\n",
    "res = get_gmm_estimates(gmm, im_list, rupture, dfstations, stations = True)\n",
    "filepath = 'stations_im_' + args['IM'] + '_gmm_' + args['GMM'] + '.npz'\n",
    "np.savez(path_data + filepath, **res)\n",
    "\n",
    "# GMM estimates at sites of surveyed buildings\n",
    "res = get_gmm_estimates(gmm, im_list, rupture, dfsurvey, stations = False)\n",
    "filepath = 'survey_im_' + args['IM'] + '_gmm_' + args['GMM'] + '.npz'\n",
    "np.savez(path_data + filepath, **res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gridded sites for map visualizations**\n",
    "\n",
    "For visualization purposes we also compute the GMM estimates at gridded sites over a specified region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgridmap = pd.read_csv(path_data + 'gridmap.csv')\n",
    "res = get_gmm_estimates(gmm, im_list, rupture, dfgridmap, stations = False)\n",
    "filepath = 'gridmap_im_' + args['IM'] + '_gmm_' + args['GMM'] + '.npz'\n",
    "np.savez(path_data + filepath, **res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licence information\n",
    "\n",
    "The OpenQuake Engine is released under the [GNU Affero Public License 3](https://github.com/gem/oq-engine/blob/master/LICENSE). Neither this tutorial nor OpenQuake are distributed with BayesFrag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openquake",
   "language": "python",
   "name": "openquake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
