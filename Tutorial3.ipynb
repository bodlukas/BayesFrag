{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesFrag - Tutorial 3: Computation of GMM estimates using OpenQuake\n",
    "\n",
    "To avoid any additional dependency on a specific ground motion model (GMM) library, the GMM estimates are computed prior and separate to the fragility parameter estimation. This tutorial explains how to perform these computations using OpenQuake as the GMM library and based on the example of the 2009 L'Aquila (Italy) earthquake. \n",
    "\n",
    "The GMM estimates consists of the mean log IM\n",
    "\n",
    "$\\ln im_{ik} = m(\\mathbf{site}_i, \\mathbf{rup}_k) + \\delta B_k + \\delta W_{ik}$\n",
    "\n",
    "$p(\\ln im_i|\\mathbf{rup}) = \\mathcal{N}\\left(\\mu_i\\, , \\, \\sqrt{\\tau_i^2 + \\phi_i^2}\\right)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import openquake.hazardlib as oq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join('data', 'twodim', '')\n",
    "\n",
    "args = {\n",
    "    'im_string': 'SAT0_300',\n",
    "    'GMM': 'BindiEtAl2011',\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify earthquake rupture \n",
    "\n",
    "The rupture metadata is from ESM: https://esm-db.eu/#/event/IT-2009-0009 \n",
    "\n",
    "The rupture geometry is from INGV: http://shakemap.ingv.it/shake4/downloadPage.html?eventid=1895389 \n",
    "The latter is identical to the ESM rupture geometry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = oq.geo.point.Point\n",
    "PlanarSurface = oq.geo.surface.planar.PlanarSurface\n",
    "MultiSurface = oq.geo.surface.multi.MultiSurface\n",
    "BaseRupture = oq.source.rupture.BaseRupture\n",
    "\n",
    "f = open(path_data + 'rupture.json')\n",
    "rup_temp = json.load(f)\n",
    "f.close()\n",
    "rup_geom_json = rup_temp['features'][0]['geometry']\n",
    "rup_geom = np.array(rup_geom_json['coordinates'][0][0])[:-1,:]\n",
    "\n",
    "rupture_surface = PlanarSurface.from_corner_points(\n",
    "    top_left = Point(rup_geom[0, 0], rup_geom[0, 1], rup_geom[0, 2]),\n",
    "    top_right = Point(rup_geom[1, 0], rup_geom[1, 1], rup_geom[1, 2]),\n",
    "    bottom_right = Point(rup_geom[2, 0], rup_geom[2, 1], rup_geom[2, 2]),\n",
    "    bottom_left = Point(rup_geom[3, 0], rup_geom[3, 1], rup_geom[3, 2]),\n",
    ")\n",
    "rupture = BaseRupture(mag = 6.1, rake = -90.0, \n",
    "                    tectonic_region_type = 'Active Shallow Crust', \n",
    "                    hypocenter = Point(longitude = 13.380, \n",
    "                                        latitude = 42.342,\n",
    "                                        depth = 8.3),\n",
    "                    surface = rupture_surface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import site information\n",
    "\n",
    "**Station data**\n",
    "\n",
    "Below, we import the station data file and print the available attributes, which are:\n",
    "- id: Station identifier\n",
    "- Longitude, Latitude in decimal degrees\n",
    "- vs30: time-averaged shear wave velocity in m/s\n",
    "- vs30measured: A boolean flag, whether vs30 was measured or deduced from other informations\n",
    "\n",
    "Besides this information, the station data also contains observed intensity measures (IMs) as processed from the ground motion recordings. In this example, we have data for four IMs: PGA, SA(0.2s), SA(0.3s), and SA(0.6s). Each of these IMs were processed according to two IM definitions: the geometric mean and the rotD50. GMMs are derived for a specific IM definition and if we aim to include the station observations we should extract the correct definition of the employed GMM. This is discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'Longitude' 'Latitude' 'vs30' 'vs30measured' 'rotD50_logPGA'\n",
      " 'geoM_logPGA' 'rotD50_logSAT0_200' 'geoM_logSAT0_200'\n",
      " 'rotD50_logSAT0_300' 'geoM_logSAT0_300' 'rotD50_logSAT0_600'\n",
      " 'geoM_logSAT0_600']\n"
     ]
    }
   ],
   "source": [
    "dfstations = pd.read_csv(path_data + 'stations.csv')\n",
    "print(dfstations.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Damage survey data**\n",
    "\n",
    "Below, we import the station data file and print the available attributes, which are:\n",
    "- id: Station identifier\n",
    "- Longitude, Latitude in decimal degrees\n",
    "- vs30: time-averaged shear wave velocity in the upper-most 30 meters of soil in m/s\n",
    "- BuildingClass: Used for fragility function estimation (-> see Tutorials 1 and 2)\n",
    "- DamageState: Used for fragility function estimation (-> see Tutorials 1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id' 'Longitude' 'Latitude' 'vs30' 'BuildingClass' 'DamageState']\n"
     ]
    }
   ],
   "source": [
    "dfsurvey = pd.read_csv(path_data + 'survey.csv')\n",
    "print(dfsurvey.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute GMM estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['GMM'] == 'BindiEtAl2011':\n",
    "    gmm = oq.gsim.bindi_2011.BindiEtAl2011()\n",
    "elif args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "    gmm = oq.gsim.chiou_youngs_2014.ChiouYoungs2014Italy()\n",
    "\n",
    "# Extract whether IM is defined for the geometric mean or RotD50\n",
    "im_definition = gmm.DEFINED_FOR_INTENSITY_MEASURE_COMPONENT.value\n",
    "if im_definition == 'Average Horizontal':\n",
    "    obs_str = 'geoM_log' + args['im_string']\n",
    "elif im_definition == 'Average Horizontal (RotD50)':\n",
    "    obs_str = 'rotD50_log' + args['im_string']\n",
    "\n",
    "if args['im_string'] == 'PGA':\n",
    "    im_list = [oq.imt.PGA()]\n",
    "else:\n",
    "    T = float('.'.join( args['im_string'][3:].split('_') )) \n",
    "    im_list = [oq.imt.SA(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for bookkeeping\n",
    "\n",
    "def get_epiazimuth(rupture, sites_mesh):\n",
    "    lon, lat = rupture.hypocenter.longitude, rupture.hypocenter.latitude\n",
    "    lons, lats = sites_mesh.lons, sites_mesh.lats    \n",
    "    return oq.geo.geodetic.fast_azimuth(lon, lat, lons, lats)\n",
    "\n",
    "def get_RuptureContext(rupture, sites_mesh, sites_vs30, \n",
    "                sites_vs30measured=None, sites_z1pt0=None):\n",
    "\n",
    "    rctx = oq.contexts.RuptureContext()\n",
    "    rctx.rjb = rupture.surface.get_joyner_boore_distance(sites_mesh)\n",
    "    rctx.rrup = rupture.surface.get_min_distance(sites_mesh)\n",
    "    rctx.vs30 = sites_vs30\n",
    "    rctx.mag = rupture.mag * np.ones_like(rctx.rjb)\n",
    "    rctx.rake = rupture.rake * np.ones_like(rctx.rjb)\n",
    "    rctx.rx = rupture.surface.get_rx_distance(sites_mesh)\n",
    "    rctx.ztor = rupture.surface.get_top_edge_depth() * np.ones_like(rctx.rjb)\n",
    "    rctx.dip = rupture.surface.get_dip() * np.ones_like(rctx.rjb)\n",
    "    if sites_z1pt0 is None:\n",
    "        rctx.z1pt0 = -7.15/4 * np.log( (sites_vs30**4 + 571**4) / (1360**4 + 571**4) )\n",
    "    else: \n",
    "        rctx.z1pt0 = sites_z1pt0\n",
    "    if sites_vs30measured is None:\n",
    "        rctx.vs30measured = False\n",
    "    else:\n",
    "        rctx.vs30measured = sites_vs30measured\n",
    "    return rctx    \n",
    "\n",
    "def compute_GMM(gmm, im_list, rupture_context):\n",
    "    n = len(rupture_context.vs30)\n",
    "    nim = len(im_list)\n",
    "    mean = np.zeros([nim, n])\n",
    "    sigma = np.zeros([nim, n])\n",
    "    tau = np.zeros([nim, n])\n",
    "    phi = np.zeros([nim, n])\n",
    "    gmm.compute(rupture_context, im_list, mean, sigma, tau, phi)\n",
    "    return {'mu_logIM': mean.squeeze(), \n",
    "            'tau_logIM': tau.squeeze(), \n",
    "            'phi_logIM': phi.squeeze()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the sites of seismic network stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfstations.copy()\n",
    "dfgmm = df[['id']].copy()\n",
    "\n",
    "sites_mesh = oq.geo.mesh.Mesh(df['Longitude'].values, df['Latitude'].values, depths=None)\n",
    "\n",
    "if args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "    # Epicentral azimuth is required for spatial correlation model of BodenmannEtAl2023.\n",
    "    dfgmm['epiazimuth'] = get_epiazimuth(rupture, sites_mesh).squeeze()\n",
    "    # dfgmm['epiazimuth'] = rupture.surface.get_azimuth(sites_mesh).squeeze()\n",
    "\n",
    "# Extract Observed IM\n",
    "dfgmm['obs_logIM'] = df[obs_str].values\n",
    "\n",
    "# Compute GMM estimates\n",
    "rupture_context = get_RuptureContext(rupture, sites_mesh, \n",
    "                                     sites_vs30 = df['vs30'].values, \n",
    "                                     sites_vs30measured = df['vs30measured'].values)\n",
    "\n",
    "res_GMM = compute_GMM(gmm, im_list, rupture_context)\n",
    "\n",
    "for key in res_GMM.keys():\n",
    "    dfgmm[key] = res_GMM[key].squeeze()\n",
    "\n",
    "dfgmm.to_csv(path_data + 'stations_im_' + args['im_string'] + '_gmm_' + args['GMM'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the sites of surveyed buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfsurvey.copy()\n",
    "dfgmm = df[['id']].copy()\n",
    "\n",
    "sites_mesh = oq.geo.mesh.Mesh(df['Longitude'].values, df['Latitude'].values, depths=None)\n",
    "\n",
    "if args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "    # Epicentral azimuth is required for spatial correlation model of BodenmannEtAl2023.\n",
    "    dfgmm['epiazimuth'] = get_epiazimuth(rupture, sites_mesh).squeeze()\n",
    "\n",
    "# Compute GMM estimates\n",
    "rupture_context = get_RuptureContext(rupture, sites_mesh, \n",
    "                                     sites_vs30 = df['vs30'].values)\n",
    "\n",
    "res_GMM = compute_GMM(gmm, im_list, rupture_context)\n",
    "\n",
    "for key in res_GMM.keys():\n",
    "    dfgmm[key] = res_GMM[key].squeeze()\n",
    "\n",
    "dfgmm.to_csv(path_data + 'survey_im_' + args['im_string'] + '_gmm_' + args['GMM'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data + 'gridmap.csv')\n",
    "\n",
    "dfgmm = df[['id']].copy()\n",
    "\n",
    "sites_mesh = oq.geo.mesh.Mesh(df['Longitude'].values, df['Latitude'].values, depths=None)\n",
    "\n",
    "if args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "    # Epicentral azimuth is required for spatial correlation model of BodenmannEtAl2023.\n",
    "    dfgmm['epiazimuth'] = get_epiazimuth(rupture, sites_mesh).squeeze()\n",
    "\n",
    "# Compute GMM estimates\n",
    "rupture_context = get_RuptureContext(rupture, sites_mesh, \n",
    "                                     sites_vs30 = df['vs30'].values)\n",
    "\n",
    "res_GMM = compute_GMM(gmm, im_list, rupture_context)\n",
    "\n",
    "for key in res_GMM.keys():\n",
    "    dfgmm[key] = res_GMM[key].squeeze()\n",
    "\n",
    "dfgmm.to_csv(path_data + 'gridmap_im_' + args['im_string'] + '_gmm_' + args['GMM'] + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openquake",
   "language": "python",
   "name": "openquake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
