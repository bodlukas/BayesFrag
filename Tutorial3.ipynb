{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesFrag - Tutorial 3: Computation of GMM estimates using OpenQuake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import openquake.hazardlib as oq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.getcwd() + os.sep + 'data_twodim' + os.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rupture information\n",
    "\n",
    "The rupture metadata is from ESM: https://esm-db.eu/#/event/IT-2009-0009 \n",
    "\n",
    "The rupture geometry is from INGV: http://shakemap.ingv.it/shake4/downloadPage.html?eventid=1895389 \n",
    "The latter is identical to the ESM rupture geometry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Point = oq.geo.point.Point\n",
    "PlanarSurface = oq.geo.surface.planar.PlanarSurface\n",
    "MultiSurface = oq.geo.surface.multi.MultiSurface\n",
    "BaseRupture = oq.source.rupture.BaseRupture\n",
    "\n",
    "f = open(path_data + 'rupture.json')\n",
    "rup_temp = json.load(f)\n",
    "f.close()\n",
    "rup_geom_json = rup_temp['features'][0]['geometry']\n",
    "rup_geom = np.array(rup_geom_json['coordinates'][0][0])[:-1,:]\n",
    "\n",
    "rupture_surface = PlanarSurface.from_corner_points(\n",
    "    top_left = Point(rup_geom[0, 0], rup_geom[0, 1], rup_geom[0, 2]),\n",
    "    top_right = Point(rup_geom[1, 0], rup_geom[1, 1], rup_geom[1, 2]),\n",
    "    bottom_right = Point(rup_geom[2, 0], rup_geom[2, 1], rup_geom[2, 2]),\n",
    "    bottom_left = Point(rup_geom[3, 0], rup_geom[3, 1], rup_geom[3, 2]),\n",
    ")\n",
    "rupture = BaseRupture(mag = 6.1, rake = -90.0, \n",
    "                    tectonic_region_type = 'Active Shallow Crust', \n",
    "                    hypocenter = Point(longitude = 13.380, \n",
    "                                        latitude = 42.342,\n",
    "                                        depth = 8.3),\n",
    "                    surface = rupture_surface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sites information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw site information for station sites and building survey sites\n",
    "dfstations = pd.read_csv(path_data + 'stations.csv')\n",
    "dfsurvey = pd.read_csv(path_data + 'survey2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute GMM estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'im_string': 'SAT0_300',\n",
    "    'GMM': 'BindiEtAl2011',\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['GMM'] == 'BindiEtAl2011':\n",
    "    gmm = oq.gsim.bindi_2011.BindiEtAl2011()\n",
    "    # This GMM is defined for geometric mean IM \n",
    "    # (also called average horizontal)\n",
    "    obs_str = 'geoM_log' + args['im_string']\n",
    "elif args['GMM'] == 'ChiouYoungs2014Italy':\n",
    "    gmm = oq.gsim.chiou_youngs_2014.ChiouYoungs2014Italy()\n",
    "    # This GMM is defined for RotD50\n",
    "    obs_str = 'rotD50_log' + args['im_string']\n",
    "\n",
    "if args['im_string'] == 'PGA':\n",
    "    im_list = [oq.imt.PGA()]\n",
    "else:\n",
    "    T = float('.'.join( args['im_string'][3:].split('_') )) \n",
    "    im_list = [oq.imt.SA(T)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mesh = oq.geo.mesh.Mesh\n",
    "def get_EpicentralAzimuth(rupture, sites_lons, sites_lats):\n",
    "    sites_mesh = Mesh(sites_lons, \n",
    "                    sites_lats, \n",
    "                    depths=None)\n",
    "    return rupture.surface.get_azimuth(sites_mesh)\n",
    "\n",
    "def get_RuptureContext(rupture, sites_lons, sites_lats, sites_vs30, \n",
    "                sites_vs30measured=None, sites_z1pt0=None):\n",
    "    sites_mesh = Mesh(sites_lons, \n",
    "                      sites_lats, \n",
    "                      depths=None)\n",
    "    rctx = oq.contexts.RuptureContext()\n",
    "    rctx.rjb = rupture.surface.get_joyner_boore_distance(sites_mesh)\n",
    "    rctx.rrup = rupture.surface.get_min_distance(sites_mesh)\n",
    "    rctx.vs30 = sites_vs30\n",
    "    rctx.mag = rupture.mag * np.ones_like(rctx.rjb)\n",
    "    rctx.rake = rupture.rake * np.ones_like(rctx.rjb)\n",
    "    rctx.rx = rupture.surface.get_rx_distance(sites_mesh)\n",
    "    rctx.ztor = rupture.surface.get_top_edge_depth() * np.ones_like(rctx.rjb)\n",
    "    rctx.dip = rupture.surface.get_dip() * np.ones_like(rctx.rjb)\n",
    "    if sites_z1pt0 is None:\n",
    "        rctx.z1pt0 = -7.15/4 * np.log( (sites_vs30**4 + 571**4) / (1360**4 + 571**4) )\n",
    "    else: \n",
    "        rctx.z1pt0 = sites_z1pt0\n",
    "    if sites_vs30measured is None:\n",
    "        rctx.vs30measured = False\n",
    "    else:\n",
    "        rctx.vs30measured = sites_vs30measured\n",
    "    return rctx    \n",
    "\n",
    "def compute_GMM(gmm, im_list, rupture_context):\n",
    "    n = len(rupture_context.vs30)\n",
    "    nim = len(im_list)\n",
    "    mean = np.zeros([nim, n])\n",
    "    sigma = np.zeros([nim, n])\n",
    "    tau = np.zeros([nim, n])\n",
    "    phi = np.zeros([nim, n])\n",
    "    gmm.compute(rupture_context, im_list, mean, sigma, tau, phi)\n",
    "    return {'mu_logIM': mean, \n",
    "            'tau_logIM': tau, \n",
    "            'phi_logIM': phi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfstations.copy()\n",
    "\n",
    "# Epicentral azimuth may be required for some spatial correlation models\n",
    "epicentral_azimuth = get_EpicentralAzimuth(rupture, df['Longitude'].values, df['Latitude'].values)\n",
    "df['epiazimuth'] = epicentral_azimuth.squeeze()\n",
    "\n",
    "# Compute GMM estimates\n",
    "rupture_context = get_RuptureContext(rupture, df['Longitude'].values, df['Latitude'].values, \n",
    "                                        df['vs30'].values, df['vs30measured'].values)\n",
    "res_GMM = compute_GMM(gmm, im_list, rupture_context)\n",
    "for key in res_GMM.keys():\n",
    "    df[key] = res_GMM[key].squeeze()\n",
    "\n",
    "# Extract Observed IM\n",
    "df['obs_logIM'] = df[obs_str].values\n",
    "\n",
    "# Arrange final csv file to be used for fragility function estimation\n",
    "dfstations = df[['network_code', 'station_code', 'Longitude', 'Latitude', 'vs30', \n",
    "                'epiazimuth', 'mu_logIM', 'tau_logIM', 'phi_logIM', 'obs_logIM']].copy()\n",
    "dfstations.to_csv(path_data + 'stations_im_' + args['im_string'] + '_GMM_' + args['GMM'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfsurvey.copy()\n",
    "\n",
    "# Epicentral azimuth may be required for some spatial correlation models\n",
    "epicentral_azimuth = get_EpicentralAzimuth(rupture, df['Longitude'].values, df['Latitude'].values)\n",
    "df['epiazimuth'] = epicentral_azimuth.squeeze()\n",
    "\n",
    "# Compute GMM estimates\n",
    "rupture_context = get_RuptureContext(rupture, df['Longitude'].values, df['Latitude'].values, \n",
    "                                        df['vs30'].values)\n",
    "res_GMM = compute_GMM(gmm, im_list, rupture_context)\n",
    "for key in res_GMM.keys():\n",
    "    df[key] = res_GMM[key].squeeze()\n",
    "\n",
    "# # Arrange final csv file to be used for fragility function estimation\n",
    "# dfsurvey = df[['id', 'Longitude', 'Latitude', 'vs30', \n",
    "#                 'epiazimuth', 'mu_logIM', 'tau_logIM', 'phi_logIM', \n",
    "#                 'BuildingClass', 'DamageState']].copy()\n",
    "# dfsurvey.to_csv(path_data + 'survey2_im_' + args['im_string'] + '_GMM_' + args['GMM'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsurvey = df[['id', 'Longitude', 'Latitude', 'vs30', 'BuildingClass',\n",
    "                'epiazimuth', 'mu_logIM', 'tau_logIM', 'phi_logIM', \n",
    "                 ]].copy()\n",
    "dfsurvey.to_csv(path_data + 'survey2_im_' + args['im_string'] + '_GMM_' + args['GMM'] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>vs30</th>\n",
       "      <th>BuildingClass</th>\n",
       "      <th>epiazimuth</th>\n",
       "      <th>mu_logIM</th>\n",
       "      <th>tau_logIM</th>\n",
       "      <th>phi_logIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.430660</td>\n",
       "      <td>42.302485</td>\n",
       "      <td>529.93370</td>\n",
       "      <td>A</td>\n",
       "      <td>44.626553</td>\n",
       "      <td>-0.565073</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.288765</td>\n",
       "      <td>42.396429</td>\n",
       "      <td>509.20395</td>\n",
       "      <td>A</td>\n",
       "      <td>164.165307</td>\n",
       "      <td>-0.677659</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.365190</td>\n",
       "      <td>42.365922</td>\n",
       "      <td>450.50436</td>\n",
       "      <td>A</td>\n",
       "      <td>169.837767</td>\n",
       "      <td>-0.565073</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13.402773</td>\n",
       "      <td>42.348720</td>\n",
       "      <td>453.86163</td>\n",
       "      <td>A</td>\n",
       "      <td>177.774937</td>\n",
       "      <td>-0.565073</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13.400559</td>\n",
       "      <td>42.352410</td>\n",
       "      <td>455.24070</td>\n",
       "      <td>A</td>\n",
       "      <td>179.724174</td>\n",
       "      <td>-0.565073</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>4195</td>\n",
       "      <td>13.114247</td>\n",
       "      <td>42.017778</td>\n",
       "      <td>434.47626</td>\n",
       "      <td>C</td>\n",
       "      <td>77.688827</td>\n",
       "      <td>-2.456111</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>4196</td>\n",
       "      <td>13.806123</td>\n",
       "      <td>42.479776</td>\n",
       "      <td>521.24426</td>\n",
       "      <td>C</td>\n",
       "      <td>280.317427</td>\n",
       "      <td>-2.181034</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>4197</td>\n",
       "      <td>13.301170</td>\n",
       "      <td>42.288853</td>\n",
       "      <td>462.58060</td>\n",
       "      <td>C</td>\n",
       "      <td>110.153346</td>\n",
       "      <td>-0.821560</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>4198</td>\n",
       "      <td>13.428467</td>\n",
       "      <td>42.028974</td>\n",
       "      <td>392.25024</td>\n",
       "      <td>C</td>\n",
       "      <td>40.589708</td>\n",
       "      <td>-1.844378</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>4199</td>\n",
       "      <td>13.701079</td>\n",
       "      <td>42.660120</td>\n",
       "      <td>411.57858</td>\n",
       "      <td>C</td>\n",
       "      <td>250.293560</td>\n",
       "      <td>-2.422767</td>\n",
       "      <td>0.501964</td>\n",
       "      <td>0.66775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Longitude   Latitude       vs30 BuildingClass  epiazimuth  \\\n",
       "0        0  13.430660  42.302485  529.93370             A   44.626553   \n",
       "1        1  13.288765  42.396429  509.20395             A  164.165307   \n",
       "2        2  13.365190  42.365922  450.50436             A  169.837767   \n",
       "3        3  13.402773  42.348720  453.86163             A  177.774937   \n",
       "4        4  13.400559  42.352410  455.24070             A  179.724174   \n",
       "...    ...        ...        ...        ...           ...         ...   \n",
       "4195  4195  13.114247  42.017778  434.47626             C   77.688827   \n",
       "4196  4196  13.806123  42.479776  521.24426             C  280.317427   \n",
       "4197  4197  13.301170  42.288853  462.58060             C  110.153346   \n",
       "4198  4198  13.428467  42.028974  392.25024             C   40.589708   \n",
       "4199  4199  13.701079  42.660120  411.57858             C  250.293560   \n",
       "\n",
       "      mu_logIM  tau_logIM  phi_logIM  \n",
       "0    -0.565073   0.501964    0.66775  \n",
       "1    -0.677659   0.501964    0.66775  \n",
       "2    -0.565073   0.501964    0.66775  \n",
       "3    -0.565073   0.501964    0.66775  \n",
       "4    -0.565073   0.501964    0.66775  \n",
       "...        ...        ...        ...  \n",
       "4195 -2.456111   0.501964    0.66775  \n",
       "4196 -2.181034   0.501964    0.66775  \n",
       "4197 -0.821560   0.501964    0.66775  \n",
       "4198 -1.844378   0.501964    0.66775  \n",
       "4199 -2.422767   0.501964    0.66775  \n",
       "\n",
       "[4200 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsurvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = os.path.join('..', '..', 'data_aquila', \"\")\n",
    "# dfsm = pd.read_csv(data_dir + 'vs30_shakemap.csv')\n",
    "# mask = ((dfsm.Longitude >= 13.2) & (dfsm.Longitude <= 13.5) &\n",
    "#         (dfsm.Latitude >= 42.15) & (dfsm.Latitude <= 42.5))\n",
    "# df = dfsm[mask].copy()\n",
    "# rows = df.row.unique()\n",
    "# cols = df.col.unique()\n",
    "# df = dfsm[np.isin(dfsm.row.values,rows)&np.isin(dfsm.col.values,cols)].copy()\n",
    "# sh = (len(df.row.unique()), len(df.col.unique()))\n",
    "# X = df.Longitude.values.reshape(sh)\n",
    "# Y = df.Latitude.values.reshape(sh)\n",
    "# Z = df.vs30.values.reshape(sh)\n",
    "# df[['row', 'col', 'Longitude', 'Latitude', 'vs30']].to_csv(path_data + 'gridmap.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data + 'gridmap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data + 'gridmap.csv')\n",
    "\n",
    "# Epicentral azimuth may be required for some spatial correlation models\n",
    "epicentral_azimuth = get_EpicentralAzimuth(rupture, df['Longitude'].values, df['Latitude'].values)\n",
    "df['epiazimuth'] = epicentral_azimuth.squeeze()\n",
    "\n",
    "# Compute GMM estimates\n",
    "rupture_context = get_RuptureContext(rupture, df['Longitude'].values, df['Latitude'].values, \n",
    "                                        df['vs30'].values)\n",
    "res_GMM = compute_GMM(gmm, im_list, rupture_context)\n",
    "for key in res_GMM.keys():\n",
    "    df[key] = res_GMM[key].squeeze()\n",
    "\n",
    "# Arrange final csv file to be used for fragility function estimation\n",
    "dfsurvey = df[['row', 'col', 'Longitude', 'Latitude', 'vs30', \n",
    "                'epiazimuth', 'mu_logIM', 'tau_logIM', 'phi_logIM']].copy()\n",
    "dfsurvey.to_csv(path_data + 'gridmap_im' + im_string + '_' + gmm_combo + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_onedim/OneDim_buildings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    'mu_logPGA': 'mu_logIM',\n",
    "    'tau_logPGA': 'tau_logIM',\n",
    "    'phi_logPGA': 'phi_logIM',\n",
    "    'rec_logPGA': 'sim_logIM',\n",
    "    'VulClass': 'BuildingClass',\n",
    "    'obs_DS': 'DamageState'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.DamageState >= 3)\n",
    "df.loc[df[mask].index, 'DamageState'] = int(2)\n",
    "df['BuildingClass'] = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_onedim/survey_withIM_PGA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>vs30</th>\n",
       "      <th>mu_logIM</th>\n",
       "      <th>tau_logIM</th>\n",
       "      <th>phi_logIM</th>\n",
       "      <th>sim_logIM</th>\n",
       "      <th>BuildingClass</th>\n",
       "      <th>DamageState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-15.110220</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>-1.891671</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>-2.674296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>9.018036</td>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>-1.377212</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.6375</td>\n",
       "      <td>-1.744287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x  y  vs30  mu_logIM  tau_logIM  phi_logIM  sim_logIM  \\\n",
       "61  -15.110220  0   450 -1.891671     0.3581     0.6375  -2.674296   \n",
       "362   9.018036  0   450 -1.377212     0.3581     0.6375  -1.744287   \n",
       "\n",
       "     BuildingClass  DamageState  \n",
       "61               0            0  \n",
       "362              0            0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract two indices as seismic network stations\n",
    "idx_SS = [61, 362]\n",
    "dfstations = df.loc[idx_SS].copy()\n",
    "dfstations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstations.rename(columns={'sim_logIM': 'obs_logIM'}).drop(columns=['BuildingClass', 'DamageState']).to_csv('data_onedim/stations_withIM_PGA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openquake",
   "language": "python",
   "name": "openquake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
